---
title: "p8105_hw2_yy3563.Rmd"
author: "Yifei Yu"
date: "2024-10-01"
output: github_document
---

```{r}
library(tidyverse)
library(dplyr)
library(readxl)
library(haven)
```


## Problem 1

```{r}
nyc_transit = 
  read_csv("Homework2_data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
           na = c("NA", "", ".")) |> 
  janitor::clean_names() |> 
  select(line, station_name, station_latitude, station_longitude, starts_with("route"), entry, vending, entrance_type, ada) |> 
  mutate(entry = if_else(entry == "YES", 1, 0))
```

The dataset `nyc_transit` contains `line`, `station_name`, `station_latitude`, `entry`, `vending`, `entrance_type`, `ada`, and all the routes served.

One variable named `entry`, originally contained the values "YES" and "NO" to indicate whether an entrance allows entry, which has been changed into numeric values where "YES" is replaced with 1 and "NO" is replaced with 0.

The cleaning steps so far include renaming the variables name, making them into lowercase with underscores instead of space and only retain those useful variables for analysis and exclude other variables.

The dimension of the resulting dataset includes 1868 rows and 32 columns.

The data are tidy because columns are variables and observations are on the row. 

### Answering three questions

```{r}
nrow(distinct(nyc_transit, station_name, line))
```

There are 465 distinct stations.

```{r}
ada_compliant = nyc_transit |> 
  filter(ada == "TRUE") |> 
  distinct(station_name, line) |> 
  nrow()
```

84 stations are ADA compliant.

```{r}
proportion = nyc_transit |> 
  filter(entry == 1) |> 
  summarise(proportion = mean(vending == "NO"))
```

The proportion of station entrances / exits without vending allow entrance is 0.0394.

### Reformat data so that route number and route name are distinct variables.

```{r}
nyc_transit = nyc_transit |> 
  mutate(across(starts_with("route"), as.character))

nyc_transit_new = nyc_transit |> 
  pivot_longer(cols = starts_with("route"),
               names_to = "route_number",
               values_to = "route_name")
```

```{r}
station_serving_A = nyc_transit_new |> 
  filter(route_name == "A") |> 
  distinct(station_name, line) |> 
  nrow()
```

There are 60 distinct stations serve the A train.

```{r}
ada_station_serving_A = nyc_transit_new |> 
  filter(route_name == "A", ada == "TRUE") |> 
  distinct(station_name, line) |> 
  nrow()
```

Of the stations that serve the A train, 17 of them are ADA compliant.

## Problem 2

```{r}
mr_trash_wheel = 
  read_excel("Homework2_data/202409 Trash Wheel Collection Data.xlsx", 
             sheet = "Mr. Trash Wheel", range = "A2:N653") |> 
  janitor::clean_names() |> 
  mutate(sports_balls = as.integer(round(sports_balls)))
```

```{r}
professor_trash_wheel = 
  read_excel("Homework2_data/202409 Trash Wheel Collection Data.xlsx", 
             sheet = "Professor Trash Wheel", range = "A2:M120") |> 
  janitor::clean_names()
```

```{r}
gwynnda_trash_wheel = 
  read_excel("Homework2_data/202409 Trash Wheel Collection Data.xlsx", 
             sheet = "Gwynnda Trash Wheel", range = "A2:L265") |> 
  janitor::clean_names()
```

```{r}
mr_trash_wheel = mr_trash_wheel |> 
  mutate(trash_wheel = "Mr. Trash Wheel") |> 
  mutate(year = as.character(year))

professor_trash_wheel = professor_trash_wheel |> 
  mutate(trash_wheel = "Professor Trash Wheel") |> 
  mutate(year = as.character(year))

gwynnda_trash_wheel = gwynnda_trash_wheel |> 
  mutate(trash_wheel = "Gwynnda Trash Wheel") |> 
  mutate(year = as.character(year))

combined_trash_wheel = bind_rows(mr_trash_wheel, professor_trash_wheel, gwynnda_trash_wheel)
```

There are `r nrow(combined_trash_wheel)` observations in the resulting dataset, which is combined data from data from `mr_trash_wheel`, `professor_trash_wheel`, and `gwynnda_trash_wheel`.

Key variables include `dumpster`, `weight_tons`, `cigarette_butts`, `glass_bottles`, `plastic_bags`, `wrappers`, and `sports_balls`.

The total weight of trash collected by Professor Trash Wheel is
`r sum(professor_trash_wheel$weight_tons, na.rm = TRUE)` tons.

The total number of cigarette butts collected by Gwynnda in June of 2022 is `r sum(gwynnda_trash_wheel$cigarette_butts[gwynnda_trash_wheel$year == 2022 & gwynnda_trash_wheel$month == "June"], na.rm = TRUE)`


## Problem 3

```{r}
bakers = 
  read_csv("Homework2_data/gbb_datasets/bakers.csv", na = c("NA", "", ".")) |>
  janitor::clean_names() |> 
  mutate(baker_name = word(baker_name, 1))

bakes = 
  read_csv("Homework2_data/gbb_datasets/bakes.csv", na = c("NA", "", ".")) |> 
  janitor::clean_names() |> 
  rename(baker_name = baker)

results = 
  read_csv("Homework2_data/gbb_datasets/results.csv", na = c("NA", "", "."), 
           skip = 2) |> 
  janitor::clean_names() |> 
  rename(baker_name = baker)
```

#### Check for completeness
```{r}
summary(bakers)
summary(bakes)
summary(results)
```

```{r}
anti_join(bakers, bakes, by = "baker_name")
anti_join(bakers, results, by = "baker_name")
anti_join(results, bakes, by = "baker_name")
```

```{r}
merged_data = left_join(bakers, bakes, by = c("baker_name", "series"))
final_data = left_join(bakers, bakes, by = c("baker_name", "series"))
```

```{r}
final_data = pivot_wider(final_data,
  names_from = episode,
  values_from = c(signature_bake, show_stopper)
)
```

### Export the result as CSV
```{r}
write_csv(final_data, "Homework2_data/gbb_datasets/final_data.csv") 
```

### Describe the data cleaning process

After importing all the three datasets, I noticed that `bakers` and `results` both have a variable named `baker`, while `bakes` has a variable named `baker_name`. So I rename the two variables into `baker_name` to ensure consistency.

The value of `baker_name` in `bakers` is the full name, while other two datasets only have the first name, so I changed the full name into first name in `bakers`. However, this decision makes the value duplicated when merging the three datasets. Therefore, another variable named `series` was also used when merging in order to ensure the accuracy of the data.

After merging, the data looks not very tidy because observations are repeated for the same individual bakers, then I used pivot_wider function to tidy the data.






